---
title: "Problem Set 1"
author: 
date: 
output: html_document
---

```{r setup, include=FALSE}
# this prevents package loading message from appearing in the rendered version of your problem set
knitr::opts_chunk$set(echo = TRUE, warning = FALSE,
                      message = FALSE)
```

Note: Grading is based both on your graphs and verbal explanations. Follow all best practices as discussed in class, including choosing appropriate parameters for all graphs. *Do not expect the assignment questions to spell out precisely how the graphs should be drawn. Sometimes guidance will be provided, but the absense of guidance does not mean that all choices are ok.*

Read *Graphical Data Analysis with R*, Ch. 3

### 1. Education and Income

[8 points]

Data: *ex0525* in the **Sleuth3** package

a) Draw multiple horizontal boxplots of `Income2005`, by `Educ` (education level). Order the boxplots from lowest educational level at the bottom to highest educational level at the top. (Hint: reorder factor levels) What do you observe?

```{r}
library(ggplot2)
library(Sleuth3)
library(gridExtra)
library(tidyverse)
library(ggridges)
options(scipen=999)

data <- ex0525
#Reorder Education levels by bringing "<12" to first position
data$Educ <- relevel(ex0525$Educ, "<12")

ggplot(data, aes(Educ, Income2005)) + 
    geom_boxplot() +
    coord_flip() +
    xlab("Education Level") +
    theme_grey(16) +
    ggtitle("Boxplot of Income By Education Levels") +
    xlab("Income") +
    ylab("Education Level")
```

From the plot, it is clearly evident that Income and Education are directly proportional. Higher the education level, higher the median income. The number and spread of outliers also increases with the education level. Furthermore, outliers are present only towards right of the boxplots, indicating a right skewness in the distribution.



b) Draw histograms, faceted by `Educ`, for the same data. Describe one insight that was not visible in the boxplots.

```{r}
ggplot(data, aes(x = Income2005)) + 
     geom_histogram(bins=50) + 
     facet_wrap(~ Educ, nrow = 2) +
     ggtitle("Histogram Faceted by Education Level") +
     xlab("Income") +
     ylab("Count of Individuals")
```

The number of data points in each of the education level was not visible in the boxplot. The histrogram shows that the data corresponding to extreme Education Levels (<12, 16 and >16) is quite less as compared to 12 and 13-15 Education Levels.
Also, the shape of distribution is more evident in the histogram. We observe all of them to be unimodal and are right skewed.


c) Plot overlapping density curves of the same data, one curve per education level, on a single set of axes. Each curve should be a different color. What additional information do you learn? 

```{r}
ggplot(data, aes(x=Income2005, color=Educ)) + 
     geom_density() +
     ggtitle("Density Curve") +
     xlab("Income") +
     ylab("Density")
```

This plot helps us understand the distribution and variance of incomes in different education levels. The lower education levels have a higher peak and smaller spread, implying, everyone has almost similar incomes. While the spread/range of incomes increases as education level increases.

### 2. Boundaries

[4 points]

a) Find or create a small dataset (< 100 observations) for which right open and right closed histograms for the same parameters are not identical. Display the full dataset (that is, show the numbers) and the plots of the two forms.

A dataset of size 50 is created by randomly sampling integers from 1 to 10 with replacement. Following are the histograms for the same dataset with right open and right closed bins:

```{r}
#Randomly sampling 50 integers from 1-10 with replacement
temp_data = sample.int(10, 50, replace=T)

#Plot side-by-side
par(mfrow=c(1,2))
hist(temp_data, right=T, main='Right Closed Histogram', xlab="Data", ylab="Count")
hist(temp_data, right=F, main='Right Open Histogram', xlab="Data", ylab="Count")
```

The difference created in the histograms due to inclusion/exclusion of boundary data points in clearly evident. 
Left plot shows Left Open, Right Closed Intervals. For example: (2,4] is one of the bins wherein 2 is excluded but 4 is included in the interval. 
Right plot shows Right Open, Left Closed Intervals. For example: [2,4) is one of the bins wherein 2 is included but 4 is excluded from the interval. 

b) Adjust parameters--the same for both--so that the right open and right closed versions become identical. Explain your strategy.

```{r}
#Plot side-by-side
par(mfrow=c(1,2))

hist(temp_data, right=T, breaks=seq(0.01,10.01,2), main='Right Closed Histogram', xlab="Data", ylab="Count")
hist(temp_data, right=F, breaks=seq(0.01,10.01,2), main='Right Open Histogram', xlab="Data", ylab="Count")
```

The fact that the dataset contains only integers can be exploited to get identical histograms. The strategy used is that we shift the bins by a small amount (0.01 in this example). So, an interval (2,4] now becomes (2.01, 4.01]. As we are not expecting any of the datapoints to be non-integers, there is no chance of getting a datapoint on the boundary of the interval. Hence, this small shift will ensure identical versions of the histograms.

### 3. Beavers

[8 points]

a) Use QQ (quantile-quantile) plots with theoretical normal lines to compare `temp` for the built-in `beaver1` and `beaver2` datasets.  Which appears to be more normally distributed?

```{r}
 larry <- with(beaver1, {
   qqnorm(temp, main = "Beaver 1")
   qqline(temp)
 })
```
```{r}
 lawrence <- with(beaver2, {
   qqnorm(temp, main = "Beaver 2")
   qqline(temp)
 })
```

The distribution of the temp variable appears to be more normal in the Beaver 1 dataset. A perfectly normal distribution would lie perfectly on the line in the plot - obviously neither temp is perfectly normal. However, the Beaver1 dataset at least lies on the line for a bit more than a third of the graph. It is on the edges where it is not normal. In contrast, the Beaver2 dataset has almost no continuous stretch on the theoretical normal, suggesting it is much further from being normal.


b) Draw density histograms with density curves and theoretical normal curves overlaid. Does the data appear to be normally distributed?

```{r}
larry <- ggplot(beaver1, aes(temp))+
         geom_histogram(aes(y = ..density..))+
  geom_density()+
  ggtitle("Beaver 1")+
  stat_function(fun=dnorm, args= list(mean=mean(beaver1$temp), sd = sd(beaver1$temp)), color = "red")


lawrence <- ggplot(beaver2, aes(temp))+
  geom_histogram(aes(y = ..density..))+
  geom_density()+
  ggtitle("Beaver 2") +
  stat_function(fun=dnorm, args= list(mean=mean(beaver2$temp), sd = sd(beaver2$temp)), color = "red")
grid.arrange(larry, lawrence, nrow = 1)
```

The Beaver1 dataset appears to be nearly, but not quite, normally distributed. In particular, the extra mode to the right of the median is distinctly not normal. However, it is much more normally distributed than the Beaver2 dataset, which is bi-modal.

c) Perform the Shapiro-Wilk test for normality using the `shapiro.test()` function and interpret the results. 

```{r}
resi1 <- shapiro.test(beaver1$temp)
resi1

resi2 <- shapiro.test(beaver2$temp)
resi2
```

The results of the test suggest we should likely reject normality for both datasets. The Beaver2 dataset scores a p-value of virtually 0 - we thus reject the null hypothesis of a normal distribution for any reasonable confidence level. The Beaver1 dataset has a higher p-value - about 0.013 - making interpretation a bit trickier. While this means we would reject the null hypothesis of normality at many confidence levels (e.g. alphas of 0.1 or 0.05), we would not reject it all reasonable confidence levels (e.g. we cannot reject normality with an alpha of 0.01). Thus, we conclude that the dataset is probably not normally distributed, but if the downside of incorrectly rejecting this hypothesis was large we would likely not do so.

d) Did all of the methods for testing for normality (a, b, and c) produce the same results? Briefly explain.

The different analyses didn't have exactly the same results, as they are all quite different in nature, but they do all lend themselves towards the same conclusion. The temp variable in the Beaver1 dataset is probably not normal, but it is closer to normal in it's distribution (and therefore more likely to be normal in truth) than the temp in Beaver2.


### 4. Doctors

[4 points]

Draw two histograms of the number of deaths attributed to coronary artery disease among doctors in the *breslow* dataset (**boot** package), one for smokers and one for non-smokers. *Hint: read the help file ?breslow to understand the data.*

```{r}
library(boot)
ggplot(breslow) + 
     geom_bar(aes(x = age, y=y), stat = "identity", width=1) + 
     facet_wrap(~ smoke, nrow = 2, labeller = labeller(smoke = 
    c("0" = "Non-Smoker",
      "1" = "Smoker"))) +
     ggtitle("Histogram for Smokers and Non-Smokers") +
     xlab("Age") +
     ylab("Number of Deaths")

```

### 5. Nutrition

[6 points]

Data: `NutritionStudy` in the **Lock5withR** package

a) Create a new categorical variable that represents ages in 10-year groups: 0-10, 11-20, 21-30, etc. Choose one of the continuous variables in the dataset and create a ridgeline plot (**ggridges** package) showing the distribution of the chosen variable by age. 

```{r}
df_use <- Lock5withR::NutritionStudy

df_use <- mutate(df_use, age_group = paste(as.character(floor(Age/10)*10), "s", sep = ""))


ggplot(df_use, aes(x = Calories, y = age_group, fill = age_group)) +
  geom_density_ridges() +
  theme_ridges() +
  theme(legend.position = "none")
```

b) Display the same data as in part a) using boxplots. 

```{r}
ggplot(df_use, aes(x = age_group, y = Calories)) + geom_boxplot(varwidth = TRUE)
```

c) Compare a) and b). Which do you think is more effective for this data and why?

Both ridgelines and boxplots are useful for understanding the data. Which is more effective for this data is very dependent on both the audience and their interests. For example, boxplots are not the easiest plots to read for non-technical stakeholders - if the goal for this data is to help to help sales reps for a diet pill understand how much each age group eats then boxplots may not be easily interpreted and the ridgeline will be more effective. It would also be effective for an audience that cares about understanding the distributions (e.g. boxplots do not give any indication of the near-bi-modal distribution of the calories eaten by people in their 50s).

Conversely, public health experts well versed in reading data visualizations may be an audience for which boxplots are more effective, as they give more exact information. Reading this graph would tell the experts about the interquartile range as well as outliers in the population, information that they could not easily glean from the ridgelines. 

In general, I would argue that ridgelines are most effective for understanding general population trends and differences, and boxplots are more useful for someone with a solid working knowledge of both the data and how to read data visualization who wants more detail.